/******************************************************************************
 *              dlf_2.1.7-6_to_2.1.7-7.sql
 *
 * This file is part of the Castor project.
 * See http://castor.web.cern.ch/castor
 *
 * Copyright (C) 2003  CERN
 * This program is free software; you can redistribute it and/or
 * modify it under the terms of the GNU General Public License
 * as published by the Free Software Foundation; either version 2
 * of the License, or (at your option) any later version.
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 * You should have received a copy of the GNU General Public License
 * along with this program; if not, write to the Free Software
 * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
 *
 * @(#)$RCSfile: dlf_2.1.7-6_to_2.1.7-7.sqlplus,v $ $Release: 1.2 $ $Release$ $Date: 2008/05/21 08:45:45 $ $Author: waldron $
 *
 * This script upgrades a CASTOR v2.1.7-6 DLF database to 2.1.7-7
 *
 * @author Castor Dev team, castor-dev@cern.ch
 *****************************************************************************/

/* Stop on errors - this only works from sqlplus and sql developer */
WHENEVER SQLERROR EXIT FAILURE;

/* Version cross check and update */
DECLARE
  unused VARCHAR(100);
BEGIN
  SELECT release INTO unused FROM dlf_version WHERE release LIKE '2_1_7_6%';
EXCEPTION WHEN NO_DATA_FOUND THEN
  -- Error, we can't apply this script
  raise_application_error(-20000, 'PL/SQL revision mismatch. Please run previous upgrade scripts before this one.');
END;
/

UPDATE dlf_version SET release = '2_1_7_7';
COMMIT;

/* Remove scheduler jobs before recreation */
BEGIN
  FOR a IN (SELECT job_name FROM user_scheduler_jobs)
  LOOP
    DBMS_SCHEDULER.DROP_JOB(a.job_name, TRUE);
  END LOOP;
END;
/

/* Drop tables */
DROP TABLE DiskCacheEfficiencyStats;

/* SQL statement for table DiskCacheEfficiencyStats */
CREATE TABLE DiskCacheEfficiencyStats (timestamp DATE NOT NULL, interval NUMBER, type VARCHAR2(255), svcclass VARCHAR2(255), wait NUMBER, d2d NUMBER, recall NUMBER, staged NUMBER, total NUMBER) 
  PARTITION BY RANGE (timestamp) (PARTITION MAX_VALUE VALUES LESS THAN (MAXVALUE));

/* SQL statement for table TapeRecalledStats */
CREATE TABLE TapeRecalledStats (timestamp DATE NOT NULL, interval NUMBER, type VARCHAR2(255), username VARCHAR2(255), groupname VARCHAR2(255), tapeVid VARCHAR2(255), tapeStatus VARCHAR2(255), files NUMBER, totalSize NUMBER, mountsPerDay NUMBER)
  PARTITION BY RANGE (timestamp) (PARTITION MAX_VALUE VALUES LESS THAN (MAXVALUE));

/* SQL statement for table ProcessingTimeStats */
CREATE TABLE ProcessingTimeStats (timestamp DATE NOT NULL, interval NUMBER, daemon VARCHAR2(255), type VARCHAR2(255), requests NUMBER, minTime NUMBER(*,4), maxTime NUMBER(*,4), avgTime NUMBER(*,4), stddevTime NUMBER(*,4), medianTime NUMBER(*,4))
  PARTITION BY RANGE (timestamp) (PARTITION MAX_VALUE VALUES LESS THAN (MAXVALUE));


/* PL/SQL method implementing statsLatency
 *
 * Provides statistics on the amount of time a user has had to wait since their 
 * request was entered into the system and it actually being served. The returned
 * data is broken down by request type.
 */
CREATE OR REPLACE PROCEDURE statsLatency (now IN DATE) AS
BEGIN
  -- Stats table: LatencyStats
  -- Frequency: 5 minutes
  FOR a IN (
    -- Translate the type to a human readable string
    SELECT CASE reqType WHEN '35'  THEN 'StageGetRequest'
                        WHEN '40'  THEN 'StagePutRequest'
                        WHEN '44'  THEN 'StageUpdateRequest'
                        WHEN '133' THEN 'StageDiskCopyReplicaRequest'
                        ELSE 'Unknown' END type, 
           count(*) started, min(waitTime) min, max(waitTime) max, 
           avg(waitTime) avg, stddev_pop(waitTime) stddev, median(waitTime) median
      FROM (
        SELECT nvl(substr(value, instr(value, '@', 1, 2) + 1, 2), 133) reqType, waitTime
          FROM (
            -- Extract the totalWaitTime for all stagerJobs or diskCopyTransfers 
            -- which have started.
            SELECT params.id, params.value waitTime
              FROM dlf_messages messages, dlf_num_param_values params
             WHERE messages.id = params.id
               AND messages.severity = 8 -- System
               AND ((messages.facility = 5  AND messages.msg_no = 12)  -- Job started
                OR  (messages.facility = 23 AND messages.msg_no = 25)) -- DiskCopyTransfer started
               AND messages.timestamp >  now - 10/1440
               AND messages.timestamp <= now - 5/1440
               AND params.name = 'TotalWaitTime'
               AND params.timestamp >  now - 10/1440
               AND params.timestamp <= now - 5/1440
          ) results
      -- For facility 23 (DiskCopyTransfer) we can assume that the request type
      -- associated with the transfer is 133 (StageDiskCopyReplicaRequest). 
      -- However, for normal jobs we must parse the Arguments attribute of the
      -- start message to determine the request type. Hence the left join, 
      -- NULL's are 133!!
      LEFT JOIN dlf_str_param_values params
        ON results.id = params.id
       AND params.name = 'Arguments'
       AND params.timestamp >  now - 10/1440
       AND params.timestamp <= now - 5/1440)
     GROUP BY reqType 
     ORDER BY type
  )
  LOOP
    INSERT INTO LatencyStats 
      (timestamp, interval, type, started, minTime, maxTime, avgTime, stddevTime, medianTime)
    VALUES (now - 5/1440, 300, a.type, a.started, a.min, a.max, a.avg, a.stddev, a.median);
  END LOOP;
END;
/


/* PL/SQL method implementing statsQueueTime
 *
 * Provides statistics on the queue time of requests in LSF broken down by request
 * type and service class.
 */
CREATE OR REPLACE PROCEDURE statsQueueTime (now in DATE) AS
BEGIN
  -- Stats table: QueueTimeStats
  -- Frequency: 5 minutes
  FOR a IN (
     SELECT type, svcclass, count(*) dispatched,
           nvl(min(params.value), 0) min, 
           nvl(max(params.value), 0) max, 
           nvl(avg(params.value), 0) avg, 
           nvl(stddev_pop(params.value), 0) stddev, 
           nvl(median(params.value), 0) median           
       FROM (
         -- Extract the type and service class for all jobs dispatched by LSF
         SELECT messages.id,
                max(decode(params.name, 'Type',     params.value, NULL)) type,
                max(decode(params.name, 'SvcClass', params.value, NULL)) svcclass
           FROM dlf_messages messages, dlf_str_param_values params
          WHERE messages.id = params.id
            AND messages.severity = 8 -- System
            AND messages.facility = 9 -- Scheduler
            AND messages.msg_no = 34  -- Wrote notification file
            AND messages.timestamp >  now - 10/1440
            AND messages.timestamp <= now - 5/1440
            AND params.name IN ('Type', 'SvcClass')
            AND params.timestamp >  now - 10/1440
            AND params.timestamp <= now - 5/1440
          GROUP BY messages.id
       ) results
      -- Attach the QueueTime attribute to the results previously collected.
      -- After this we will have a line for each started job detailing the
      -- service class the job is destined for, the request type and the number
      -- of seconds it spent queued.
      INNER JOIN dlf_num_param_values params
         ON results.id = params.id
        AND params.name = 'QueueTime'
        AND params.timestamp >  now - 10/1440
        AND params.timestamp <= now - 5/1440
      GROUP BY type, svcclass
      ORDER BY type, svcclass
  )
  LOOP
    INSERT INTO QueueTimeStats 
      (timestamp, interval, type, svcclass, dispatched, minTime, maxTime, avgTime, stddevTime, medianTime)
    VALUES (now - 5/1440, 300, a.type, a.svcclass, a.dispatched, a.min, a.max, a.avg, a.stddev, a.median);
  END LOOP;
END;
/


/* PL/SQL method implementing statsGarbageCollection 
 *
 * Provides an overview of the garbage collection process which includes the number
 * of files removed during the last interval, the total volume of reclaimed space
 * and statistical information e.g. avg on the fileage of the files deleted.
 */
CREATE OR REPLACE PROCEDURE statsGarbageCollection (now IN DATE) AS
BEGIN
  -- Stats table: GarbageCollectionStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT hostname diskserver, type, count(*) deleted,
           sum(params.value) totalSize, 
           min(fileAge) min,
           max(fileAge) max, 
           avg(fileAge) avg, 
           stddev_pop(fileAge) stddev, 
           median(fileAge) median
     FROM (
       -- Extract the file age of all files successfully removed across all
       -- diskservers.
       SELECT messages.id, messages.hostid, 
              decode(messages.msg_no, 11, 'Files2Delete', 
              decode(messages.msg_no, 27, 'NsFilesDeletd', 'StgFilesDeleted')) type, 
              params.value fileAge
         FROM dlf_messages messages, dlf_num_param_values params
        WHERE messages.id = params.id
          AND messages.severity = 8 -- System
          AND messages.facility = 8 -- GC
          AND (messages.msg_no = 11 OR -- Removed file successfully
               messages.msg_no = 27 OR -- Deleting ... nameserver
               messages.msg_no = 36)   -- Deleting ... stager catalog
          AND messages.timestamp >  now - 10/1440
          AND messages.timestamp <= now - 5/1440
          AND params.name = 'FileAge'
          AND params.timestamp >  now - 10/1440
          AND params.timestamp <= now - 5/1440
     ) results
    -- Attach the file size value from the same message to the result form the
    -- inner select above. As a result we'll have one row per file with its 
    -- corresponding age and size.
    INNER JOIN dlf_num_param_values params
       ON results.id = params.id
      AND params.name = 'FileSize'
      AND params.timestamp >  now - 10/1440
      AND params.timestamp <= now - 5/1440
    -- Resolve the host ids to names
    INNER JOIN dlf_host_map hosts
       ON results.hostid = hosts.hostid
    GROUP BY hostname, type
    ORDER BY hostname, type
  )
  LOOP
    INSERT INTO GarbageCollectionStats
      (timestamp, interval, diskserver, type, deleted, totalSize, minFileAge, maxFileAge, avgFileAge, stddevFileAge, medianFileAge)
    VALUES (now - 5/1440, 300, a.diskserver, a.type, a.deleted, a.totalsize, a.min, a.max, a.avg, a.stddev, a.median);
  END LOOP;
END;
/


/* PL/SQL method implementing statsRequest
 *
 * Provides statistical information on the types of requests recorded by the request
 * handler, the total for all users and a break down of the top 5 users per request
 * type 
 */
CREATE OR REPLACE PROCEDURE statsRequest (now IN DATE) AS
BEGIN
  -- Stats table: RequestStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT type, hostname, euid, requests FROM (
      -- For each request type display the top 5 users + the total number of requests
      SELECT type, euid, hostname, requests,
             RANK() OVER (PARTITION BY type ORDER BY requests DESC, euid ASC) rank
        FROM(
          SELECT params.value type, hosts.hostname, '-' euid, count(*) requests
            FROM dlf_messages messages, dlf_str_param_values params, dlf_host_map hosts
           WHERE messages.id = params.id
             AND messages.severity = 10 -- Monitoring
             AND messages.facility = 4  -- RequestHandler
             AND messages.msg_no = 10   -- Reply sent to client
             AND messages.timestamp >  now - 10/1440
             AND messages.timestamp <= now - 5/1440
             AND params.name = 'Type'
             AND params.timestamp >  now - 10/1440
             AND params.timestamp <= now - 5/1440
             AND messages.hostid = hosts.hostid
           GROUP BY params.value, hosts.hostname
          -- Join the user and summary/aggregate level breakdowns together. Note: 
          -- this could probably be done using an analytical function or grouping 
          -- set!!!
           UNION
          -- Determine the number of requests made for each request type and per
          -- user over the last sampling period. This gives us a user level breakdown.
          SELECT results.value type, hostname, TO_CHAR(params.value) euid, count(*) requests
            FROM (
              SELECT params.id, params.value, hosts.hostname
                FROM dlf_messages messages, dlf_str_param_values params, dlf_host_map hosts
               WHERE messages.id = params.id
                 AND messages.severity = 10 -- Monitoring
                 AND messages.facility = 4  -- RequestHandler
                 AND messages.msg_no = 10   -- Reply sent to client
                 AND messages.timestamp >  now - 10/1440
                 AND messages.timestamp <= now - 5/1440
                 AND params.name = 'Type'
                 AND params.timestamp >  now - 10/1440
                 AND params.timestamp <= now - 5/1440
                 AND messages.hostid = hosts.hostid
            ) results
          -- Determine the uid of the user associated with each request
          INNER JOIN dlf_num_param_values params
             ON results.id = params.id
            AND params.name = 'Euid'
            AND params.timestamp >  now - 10/1440
            AND params.timestamp <= now - 5/1440
          GROUP BY results.value, hostname, params.value)
      ) WHERE rank < 6
     ORDER BY type, requests DESC
  )
  LOOP
    INSERT INTO RequestStats
      (timestamp, interval, type, hostname, euid, requests)
    VALUES (now - 5/1440, 300, a.type, a.hostname, a.euid, a.requests);
  END LOOP;
END;
/


/* PL/SQL method implementing statsDiskCachEfficiency 
 *
 * Provides an overview of how effectively the disk cache is performing. For example,
 * the greater the number of recalls the less effective the cache is.
 *
 * Example output:
 *   Type            SvcClass      Wait D2D  Recall Staged Total
 *   StageGetRequest dteam         0    0    0      3      3
 *   StageGetRequest compasschunks 0    0    0      1      1
 *   StageGetRequest na48          0    0    0      71     71
 *   StageGetRequest compassmdst   0    0    0      1      1
 *   StageGetRequest compass004d   0    0    0      55     55
 *   StageGetRequest compasscdr    0    0    1      1      2
 *   StageGetRequest na48goldcmp   0    0    0      154    154
 *   StageGetRequest default       0    0    0      100    100
 */
CREATE OR REPLACE PROCEDURE statsDiskCacheEfficiency (now IN DATE) AS
BEGIN
  -- Stats table: DiskCacheEfficiencyStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT type, svcclass, 
           nvl(sum(decode(msg_no, 53, requests, 0)), 0) Wait,
           nvl(sum(decode(msg_no, 56, requests, 0)), 0) D2D,
           nvl(sum(decode(msg_no, 57, requests, 0)), 0) Recall,
           nvl(sum(decode(msg_no, 60, requests, 0)), 0) Staged,
           nvl(sum(requests), 0) total
      FROM (
        SELECT type, svcclass, msg_no, count(*) requests
          FROM (
            -- Get the first message issued for all subrequests of interest. This
            -- will indicate to us whether the request was a hit or a miss.
            SELECT sum(id) KEEP (DENSE_RANK FIRST
                   ORDER BY messages.timestamp ASC, messages.timeusec ASC) id,
                   type, svcclass
              FROM (
                 -- From this select statement we have a line for every new
                 -- request entering the system that resulted in a read style
                 -- access, along with its type and associated service class
                 SELECT results.reqid, results.value type, params.value svcclass
                   FROM (
                     -- Extract all new requests processed by the request handler
                     -- for types which will involve a read.
                     SELECT messages.id, messages.reqid, params.value
                       FROM dlf_messages messages, dlf_str_param_values params
                      WHERE messages.id = params.id
                        AND messages.severity = 10 -- Monitoring
                        AND messages.facility = 4  -- RequestHandler
                        AND messages.msg_no = 10   -- Reply sent to client
                        AND messages.timestamp >  now - 10/1440
                        AND messages.timestamp <= now - 5/1440
                        AND params.name = 'Type'
                        AND params.value IN ('StageGetRequest', 
                                             'StagePrepareToGetRequest', 
                                             'StageUpdateRequest')
                        AND params.timestamp >  now - 10/1440
                        AND params.timestamp <= now - 5/1440
                   ) results
                 -- Join the service class to the previously collected results
                 INNER JOIN dlf_str_param_values params
                    ON results.id = params.id
                   AND params.name = 'SvcClass'
                   AND params.timestamp >  now - 10/1440
                   AND params.timestamp <= now - 5/1440
              ) requests
            -- For the request ids extracted above work out the subrequests which
            -- were processed by the stager.
            INNER JOIN dlf_messages messages
               ON messages.reqid = requests.reqid
              AND messages.severity = 8  -- System
              AND messages.facility = 22 -- Stager
              AND messages.msg_no IN (53, 56, 57, 60)
              AND messages.timestamp > now - 10/1440
            GROUP BY messages.subreqid, type, svcclass
          ) subreqs
        INNER JOIN dlf_messages messages
           ON subreqs.id = messages.id
          AND messages.timestamp > now - 10/1440
        GROUP BY type, svcclass, msg_no)
        GROUP BY type, svcclass
  )
  LOOP
    INSERT INTO DiskCacheEfficiencyStats
      (timestamp, interval, wait, type, svcclass, d2d, recall, staged, total)
    VALUES (now - 5/1440, 300, a.wait, a.type, a.svcclass, a.d2d, a.recall, a.staged, a.total);
  END LOOP;
END;
/


/* PL/SQL method implementing statsMigratedFiles 
 *
 * Provides statistical information on the number of files migrated to tape and the
 * total data volume transferred broken down by service class and tape pool.
 */
CREATE OR REPLACE PROCEDURE statsMigratedFiles (now IN DATE) AS
BEGIN
  -- Stats table: FilesMigratedStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT svcclass, tapepool, count(*) files, sum(params.value) totalsize
      FROM (
        -- Extract the messages to indicate when a file has been migrated
        SELECT messages.id,
               max(decode(params.name, 'SVCCLASS', params.value, NULL)) svcclass,
               max(decode(params.name, 'TAPEPOOL', params.value, NULL)) tapepool
          FROM dlf_messages messages, dlf_str_param_values params
         WHERE messages.id = params.id
           AND messages.severity = 8 -- System
           AND messages.facility = 1 -- migrator
           AND messages.msg_no = 55  -- File staged
           AND messages.timestamp >  now - 10/1440
           AND messages.timestamp <= now - 5/1440
           AND params.name IN ('SVCCLASS', 'TAPEPOOL')
           AND params.timestamp >  now - 10/1440
           AND params.timestamp <= now - 5/1440
         GROUP BY messages.id
      ) results
      -- Attach the filesize to the previously collected information
     INNER JOIN dlf_num_param_values params
        ON results.id = params.id
       AND params.name = 'FILESIZE'
       AND params.timestamp >  now - 10/1440
       AND params.timestamp <= now - 5/1440
     GROUP BY svcclass, tapepool
  )
  LOOP
    INSERT INTO FilesMigratedStats
      (timestamp, interval, svcclass, tapepool, totalFiles, totalSize)
    VALUES (now - 5/1440, 300, a.svcclass, a.tapepool, a.files, a.totalsize);
  END LOOP;
END;
/


/* PL/SQL method implementing statsReplication 
 *
 * Provides statistical information on disk copy replication requests both across
 * service classes and internally within the same service class.
 */
CREATE OR REPLACE PROCEDURE statsReplication (now IN DATE) AS
BEGIN
  -- Stats table: ReplicationStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT src, dest, count(*) transferred, sum(params.value) totalsize, 
           min(params.value) min, max(params.value) max, avg(params.value) avg, 
           stddev_pop(params.value) stddev, median(params.value) median
      FROM (
        SELECT params.id, 
               substr(params.value, 0, instr(params.value, '->', 1) - 2) src,
               substr(params.value, instr(params.value, '->', 1) + 3) dest
          FROM dlf_messages messages, dlf_str_param_values params
         WHERE messages.id = params.id
           AND messages.severity = 8  -- System
           AND messages.facility = 23 -- DiskCopyTransfer
           AND messages.msg_no = 39   -- DiskCopy Transfer successful
           AND messages.timestamp >  now - 10/1440
           AND messages.timestamp <= now - 5/1440
           AND params.name = 'Direction'
           AND params.timestamp >  now - 10/1440
           AND params.timestamp <= now - 5/1440
      ) results
     -- Attach the size of the file to each replication request. As a result of 
     -- this we will have one line per request detailing the direction of the 
     -- transfer and the amount of data transferred
     INNER JOIN dlf_num_param_values params
        ON results.id = params.id
       AND params.name = 'FileSize'
       AND params.timestamp >  now - 10/1440
       AND params.timestamp <= now - 5/1440
     GROUP BY src, dest
  )
  LOOP
    INSERT INTO ReplicationStats
      (timestamp, interval, sourceSvcClass, destSvcClass, transferred, totalSize, minSize, maxSize, avgSize, stddevSize, medianSize)
    VALUES (now - 5/1440, 300, a.src, a.dest, a.transferred, a.totalsize, a.min, a.max, a.avg, a.stddev, a.median);
  END LOOP;
END;
/


/* PL/SQL method implementing statsTapeRecalled
 *
 * Provides statistical information on who triggered a tape recall, how many files
 * were requested, the status of the tape as the request was processed and the type
 * of request that triggered the recall.
 *
 * Example output:
 *   Type                     Username Groupname TapeVID TapeStatus   Files MountsPerDay 
 *   StagePrepareToGetRequest waldron  c3        I10488	 TAPE_PENDING 10    0
 *   StagePrepareToGetRequest waldron  c3        I10487	 TAPE_PENDING 8     0
 *   StagePrepareToGetRequest waldron  c3        I10486	 TAPE_PENDING 2     0
 *   StagePrepareToGetRequest waldron  c3        I06983	 TAPE_PENDING 854   0
 */
CREATE OR REPLACE PROCEDURE statsTapeRecalled (now IN DATE) AS
BEGIN
  -- Stats table: TapeRecalledStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT type, username, groupname, results.tapevid, tapestatus, 
           count(*) files, sum(params.value) totalsize, 
           nvl(sum(mounts.mounted), 0) mounted
      FROM (
        -- Extract all requests from the stager which triggered a tape recall
        -- including the request type, username and groupname associated with
        -- that request
        SELECT messages.id, messages.tapevid,
               max(decode(params.name, 'Type',       params.value, NULL)) type,
               max(decode(params.name, 'Username',   params.value, NULL)) username,
               max(decode(params.name, 'Groupname',  params.value, NULL)) groupname,
               max(decode(params.name, 'TapeStatus', params.value, NULL)) tapestatus
          FROM dlf_messages messages, dlf_str_param_values params
         WHERE messages.id = params.id
           AND messages.severity = 8  -- System
           AND messages.facility = 22 -- Stager
           AND messages.msg_no = 57   -- Triggering Tape Recall
           AND messages.timestamp >  now - 10/1440
           AND messages.timestamp <= now - 5/1440
           AND params.name IN ('Type', 'Username', 'Groupname', 'TapeStatus')
           AND params.timestamp >  sysdate - 10/1440
           AND params.timestamp <= sysdate - 5/1440
         GROUP BY messages.id, messages.tapevid
      ) results
     -- Attach the file size to be recalled
     INNER JOIN dlf_num_param_values params
        ON results.id = params.id
       AND params.name = 'FileSize'
       AND params.timestamp >  now - 10/1440
       AND params.timestamp <= now - 5/1440
     -- Attached the number of mounts which took place for the tape over the
     -- last 24 hours
     LEFT JOIN (
       SELECT messages.tapevid, count(*) mounted
         FROM dlf_messages messages
        WHERE messages.severity = 8 -- System
          AND messages.facility = 2 -- Recaller
          AND messages.msg_no = 13  -- Recaller started
          AND messages.subreqid <> '00000000-0000-0000-0000-000000000000'
          AND messages.timestamp >  (now - 1) - 5/1440
        GROUP BY messages.tapevid) mounts
        ON results.tapevid = mounts.tapevid
     GROUP BY type, username, groupname, results.tapevid, tapestatus
  )
  LOOP
    INSERT INTO TapeRecalledStats
      (timestamp, interval, type, username, groupname, tapeVid, tapeStatus, files, totalSize, mountsPerDay)
    VALUES (now - 5/1440, 300, a.type, a.username, a.groupname, a.tapevid, a.tapestatus, a.files, a.totalsize, a.mounted);
  END LOOP;
END;
/


/* PL/SQL method implementing statsProcessingTime 
 *
 * Provides statistics on the processing time in seconds of requests in the Stager 
 * and RequestHandler daemons
 */
CREATE OR REPLACE PROCEDURE statsProcessingTime (now IN DATE) AS
BEGIN
  -- Stats table: ProcessingTimeStats
  -- Frequency: 5 minutes
  FOR a IN (
    SELECT facility.fac_name daemon, params.value type, count(*) requests, 
           min(results.value) min,
           max(results.value) max, 
           avg(results.value) avg, 
           stddev_pop(results.value) stddev, 
           median(results.value) median
      FROM (
        -- Extract all the processing time values for the Stager
        SELECT messages.id, messages.facility, params.value
          FROM dlf_messages messages, dlf_num_param_values params
         WHERE messages.id = params.id
           AND messages.severity = 10 -- Monitoring
           AND messages.facility = 22 -- Stager
           AND messages.msg_no = 25   -- Request processed
           AND messages.timestamp >  now - 10/1440
           AND messages.timestamp <= now - 5/1440
           AND params.name = 'ProcessingTime'
           AND params.timestamp >  now - 10/1440
           AND params.timestamp <= now - 5/1440
         UNION
        -- Extract all the processing time values for the RequestHandler
        SELECT messages.id, messages.facility, params.value
          FROM dlf_messages messages, dlf_num_param_values params
         WHERE messages.id = params.id
           AND messages.severity = 10 -- Monitoring
           AND messages.facility = 4  -- RequestHandler
           AND messages.msg_no = 10   -- Reply sent to client
           AND messages.timestamp >  now - 10/1440
           AND messages.timestamp <= now - 5/1440
           AND params.name = 'ElapsedTime'
           AND params.timestamp >  now - 10/1440
           AND params.timestamp <= now - 5/1440
      ) results
     -- Attach the request type
     INNER JOIN dlf_str_param_values params
        ON results.id = params.id
       AND params.name = 'Type'
       AND params.timestamp >  now - 10/1440
       AND params.timestamp <= now - 5/1440
     -- Resolve the facility number to a name
     INNER JOIN dlf_facilities facility
        ON results.facility = facility.fac_no
     GROUP BY facility.fac_name, params.value
  )
  LOOP
    INSERT INTO ProcessingTimeStats
      (timestamp, interval, daemon, type, requests, minTime, maxTime, avgTime, stddevTime, medianTime)
    VALUES (now - 5/1440, 300, a.daemon, a.type, a.requests, a.min, a.max, a.avg, a.stddev, a.median);
  END LOOP;
END;
/


BEGIN
  -- Create a db job to be run every day and create new partitions
  DBMS_SCHEDULER.CREATE_JOB(
      JOB_NAME        => 'partitionCreationJob',
      JOB_TYPE        => 'STORED_PROCEDURE',
      JOB_ACTION      => 'createPartitions',
      START_DATE      => TRUNC(SYSDATE) + 1/24,
      REPEAT_INTERVAL => 'FREQ=DAILY',
      ENABLED         => TRUE,
      COMMENTS        => 'Daily partitioning creation');

  -- Create a db job to be run every day and drop old data from the database
  DBMS_SCHEDULER.CREATE_JOB(
      JOB_NAME        => 'archiveDataJob',
      JOB_TYPE        => 'PLSQL_BLOCK',
      JOB_ACTION      => 'BEGIN archiveData(90); END;',
      START_DATE      => TRUNC(SYSDATE) + 2/24,
      REPEAT_INTERVAL => 'FREQ=DAILY',
      ENABLED         => TRUE,
      COMMENTS        => 'Daily data archiving');

  -- Create a job to execute the procedures that create statistical information
  DBMS_SCHEDULER.CREATE_JOB (
      JOB_NAME        => 'statisticJob',
      JOB_TYPE        => 'PLSQL_BLOCK',
      JOB_ACTION      => 'DECLARE
                            now DATE;
                          BEGIN
                            now := SYSDATE;
                            statsLatency(now);
                            statsQueueTime(now);
                            statsGarbageCollection(now);
                            statsRequest(now);
                            statsDiskCacheEfficiency(now);
                            statsMigratedFiles(now);
                            statsReplication(now);
                            statsTapeRecalled(now);
                            statsProcessingTime(now);
                          END;',
      START_DATE      => SYSDATE,
      REPEAT_INTERVAL => 'FREQ=MINUTELY; INTERVAL=5',
      ENABLED         => TRUE,
      COMMENTS        => 'CASTOR2 Monitoring Statistics (5 Minute Frequency)');
END;
/


/* Trigger the initial creation of partitions */
BEGIN
  createPartitions();
END;
/


/* End-of-File */
