{{- $namespace := .Release.Namespace -}}
{{- $schedulerConfig := include "scheduler.config" . | fromYaml -}}
{{- $tapeServers := include "tpsrv.tapeServers" . | fromYaml -}}
{{ include "validate.tapeServers" . }}
{{ range $name,$tapeServerConfig := $tapeServers }}
{{- $tpsrvName := $name -}}
{{- $libraryDevice := .libraryDevice -}}
apiVersion: apps/v1
kind: StatefulSet # StatefulSets enforce at most x pods semantics (in our case x=1)
metadata:
  name: {{ $tpsrvName }}
  namespace: {{ $namespace | quote }}
  labels:
    {{- include "common.labels.standard" $ | nindent 4 }}
spec:
  serviceName: {{ $tpsrvName }}  # Ensure a headless service exists with this name; allows for stable DNS entries
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: {{ $tpsrvName }}
  template:
    metadata:
      labels:
        app.kubernetes.io/name: {{ $tpsrvName }}
        {{- include "common.labels.withoutname" $ | nindent 8 }}
        cta/library-device: {{ .libraryDevice }}
        collect-varlog: "true"
      annotations:
        catalogue-schema-version: {{ $.Values.global.catalogueSchemaVersion | quote }}
    spec:
      restartPolicy: Always
      terminationGracePeriodSeconds: {{ $.Values.terminationGracePeriodSeconds }}
      imagePullSecrets:
      {{- include "tpsrv.imagePullSecrets" $ | nindent 6 }}
      containers:
      # RMCD container
      - name: rmcd
        image: {{ include "tpsrv.image" $ }}
        imagePullPolicy: {{ include "tpsrv.imagePullPolicy" $ }}
        securityContext:
          privileged: true
        stdin: true
        command: ["/opt/run/bin/rmcd.sh"]
        args: []
        readinessProbe:
          exec:
            command: ["test", "-f", "/RMCD_READY"]
          initialDelaySeconds: 5
          periodSeconds: 1
          failureThreshold: 60
        resources:
          requests:
            memory: {{ $.Values.rmcd.resources.requests.memory | quote }}
            ephemeral-storage: {{ index $.Values.rmcd.resources.requests "ephemeral-storage" | quote }}
          limits:
            memory: {{ $.Values.taped.resources.limits.memory | quote }}
            ephemeral-storage: {{ index $.Values.taped.resources.limits "ephemeral-storage" | quote }}
        env:
        - name: MY_NAME
          value: {{ $tpsrvName }}
        - name: MY_NAMESPACE
          value: {{ $namespace | quote }}
        - name: INSTANCE_NAME
          value: {{ $namespace | quote }}
        - name: LIBRARY_DEVICE
          value: {{ $libraryDevice | quote }}
        - name: MY_CONTAINER
          value: "rmcd"
        - name: TERM
          value: "xterm"
        volumeMounts:
        {{- if $.Values.global.volumeMounts }}
        {{ $.Values.global.volumeMounts | toYaml | nindent 8 }}
        {{- end }}
      # For each drive, spawn a separate taped container
      {{- range $index, $drive := .drives }}
      - name: "taped-{{ $index }}"
        image: {{ include "tpsrv.image" $ }}
        imagePullPolicy: {{ include "tpsrv.imagePullPolicy" $ }}
        securityContext:
          privileged: true
        command: ["/bin/sh", "-c"]
        args:
        - |
          cat /tmp/dump/cta/cta-tpsrv-tmp.sss.keytab > /etc/cta/cta-taped.sss.keytab;
          chmod 600 /etc/cta/cta-taped.sss.keytab;
          /opt/run/bin/taped.sh;

        readinessProbe:
          exec:
            command: ["test", "-f", "/TAPED_READY"]
          initialDelaySeconds: 5
          periodSeconds: 1
          failureThreshold: 60
        stdin: true
        env:
        - name: MY_NAME
          value: {{ $tpsrvName }}
        - name: MY_NAMESPACE
          value: {{ $namespace | quote }}
        - name: INSTANCE_NAME
          value: {{ $namespace | quote }}
        - name: MY_CONTAINER
          value: "taped-{{ $index }}"
        - name: TERM
          value: "xterm"
        - name: DRIVE_NAME
          value: {{ $drive.name }}
        - name: DRIVE_DEVICE
          value: {{ $drive.device }}
        - name: LIBRARY_DEVICE
          value: {{ $libraryDevice | quote }}
        - name: SCHEDULER_BACKEND
          value: {{ $schedulerConfig.backend | quote}}
        - name: XrdSecPROTOCOL
          value: {{ $.Values.conf.taped.secProtocol }}
        - name: XrdSecSSSKT
          value: {{ $.Values.conf.taped.secSssktPath }}/{{ $.Values.conf.taped.ctaTapedSss }}
        volumeMounts:
        - name: cta-taped-config
          mountPath: /etc/cta/cta-taped-{{ $drive.name }}.conf
          subPath: cta-taped-{{ $drive.name }}.conf
        - name: catalogue-config
          mountPath: /etc/cta/cta-catalogue.conf
          subPath: cta-catalogue.conf
        {{- if eq $schedulerConfig.backend "postgres" }}
        - name: scheduler-config
          mountPath: /etc/cta/cta-scheduler.conf
          subPath: cta-scheduler.conf
        {{- else }}
        - name: scheduler-config
          mountPath: /etc/cta/cta-objectstore-tools.conf
          subPath: cta-objectstore-tools.conf
        {{- end }}
        - mountPath: /etc/config/eos
          name: eosconfig
        - name: tpsrv-sss-keytab
          mountPath: /tmp/dump/cta/cta-tpsrv-tmp.sss.keytab
          subPath: cta-tpsrv.sss.keytab
        {{- if eq $schedulerConfig.backend "ceph" }}
        - name: cta-ceph-volume
          mountPath: /etc/ceph/ceph.conf
          subPath: ceph.conf
        - name: cta-ceph-volume
          mountPath: /etc/ceph/ceph.client.{{ $schedulerConfig.cephConfig.id }}.keyring
          subPath: ceph.client.{{ $schedulerConfig.cephConfig.id }}.keyring
        {{- end }}
        {{- if $.Values.global.volumeMounts }}
        {{ $.Values.global.volumeMounts | toYaml | nindent 8 }}
        {{- end }}
      {{- end }} # End of containers loop
      volumes:
      - name: catalogue-config
        configMap:
          name: cta-catalogue-conf
      {{- if eq $schedulerConfig.backend "postgres" }}
      - name: scheduler-config
        configMap:
          name: cta-scheduler-conf
      {{- else }}
      - name: scheduler-config
        configMap:
          name: cta-objectstore-conf
      {{- end }}
      - name: eosconfig
        configMap:
          name: eos-config-base
      {{- if eq $schedulerConfig.backend "ceph" }}
      - name: cta-ceph-volume
        configMap:
          name: ceph-conf
      {{- end }}
      {{- range $index, $drive := .drives }} # configmap for each drive in the tape server
      - name: cta-taped-config
        configMap:
          name: cta-taped-{{ lower $drive.name }}-conf
      {{- end }} # End of drive-specific configmaps loop
      - name: tpsrv-sss-keytab
        secret:
          secretName: tpsrv-sss-keytab
      {{- if $.Values.global.volumes }}
      {{ $.Values.global.volumes | toYaml | nindent 6 }}
      {{- end }}
---
{{- end }}
