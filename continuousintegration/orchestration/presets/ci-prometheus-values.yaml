extraScrapeConfigs: |
  - job_name: "otel-collector"
    static_configs:
      - targets:
        - otel-opentelemetry-collector:8888
        - otel-opentelemetry-collector:8889

rbac:
  create: true

alertmanager:
  enabled: false

kube-state-metrics:
  enabled: true

# We want to get metrics on CPU/memory usage
prometheus-node-exporter:
  enabled: true

prometheus-pushgateway:
  enabled: false

server:
  global:
    scrape_interval: 30s
    scrape_timeout: 3s

  persistentVolume:
    enabled: false

  extraSecretMounts:
    - name: prometheus-remote-write-secret
      mountPath: /etc/prometheus/secrets/remote-write
      secretName: prometheus-remote-write-secret
      readOnly: true

  remoteWrite:
    - url: "http://monit-prom-lts.cern.ch/api/v1/push"
      basic_auth:
        username_file: /etc/prometheus/secrets/remote-write/username
        password_file: /etc/prometheus/secrets/remote-write/password
      # Remote write only the time series with the ci usecase label.
      # Important so that we don't explode the cardinality of the central DB
      write_relabel_configs:
        - source_labels: ["usecase"]
          regex: "ci"
          action: keep

# Note that these max_over_time functions are designed such that we can get a total count on any counters.
# For CI this is useful, but production this is not feasible, as the time frame would need to be too long.
# However, for production, one is typically only interested in rates, so the only constraint there
# would be for the max_over_time time frame to be longer than whatever the rate queries will use.
serverFiles:
  recording_rules.yml:
    groups:
    # CTA metrics
    - name: cta-metrics
      interval: 30s
      rules:
      # Database
      - record: db_client_connection_count
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  db_namespace, db_system_name)
            (max_over_time(db_client_connection_count[1d]))
      - record: db_client_operation_duration_milliseconds_bucket
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  db_namespace, db_system_name, le)
            (max_over_time(db_client_operation_duration_milliseconds_bucket{le=~"5.0|10.0|50.0|100.0|500.0|1000.0|5000.0|10000.0|100000.0|\\+Inf"}[1d]))
      - record: db_client_operation_duration_milliseconds_count
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  db_namespace, db_system_name)
            (max_over_time(db_client_operation_duration_milliseconds_count[1d]))
      # Frontend
      - record: cta_frontend_request_duration_milliseconds_bucket
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_event_name, le)
            (max_over_time(cta_frontend_request_duration_milliseconds_bucket{le=~"5.0|10.0|50.0|100.0|500.0|1000.0|5000.0|10000.0|100000.0|\\+Inf"}[1d]))
      - record: cta_frontend_request_duration_milliseconds_count
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_event_name)
            (max_over_time(cta_frontend_request_duration_milliseconds_count[1d]))
      # Scheduler
      - record: cta_scheduler_operation_duration_milliseconds_bucket
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_scheduler_operation_name, le)
            (max_over_time(cta_scheduler_operation_duration_milliseconds_bucket{le=~"5.0|10.0|50.0|100.0|500.0|1000.0|5000.0|10000.0|100000.0|\\+Inf"}[1d]))
      - record: cta_scheduler_operation_duration_milliseconds_count
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_scheduler_operation_name)
            (max_over_time(cta_scheduler_operation_duration_milliseconds_count[1d]))

      - record: cta_objectstore_lock_acquire_duration_milliseconds_bucket
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_lock_type, le)
            (max_over_time(cta_objectstore_lock_acquire_duration_milliseconds_bucket{le=~"5.0|10.0|50.0|100.0|500.0|1000.0|5000.0|10000.0|100000.0|\\+Inf"}[1d]))
      - record: cta_objectstore_lock_acquire_duration_milliseconds_count
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_lock_type)
            (max_over_time(cta_objectstore_lock_acquire_duration_milliseconds_count[1d]))
      # Taped
      - record: cta_taped_mounts_total
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_transfer_direction)
            (max_over_time(cta_taped_mounts_total[1d]))
      - record: cta_taped_transfers_total
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_transfer_direction)
            (max_over_time(cta_taped_transfers_total[1d]))
      - record: cta_taped_thread_pool_size
        labels: { usecase: "ci" }
        expr: |
          sum by (service_namespace, service_name, service_version,
                  process_title, host_name, cta_scheduler_backend_name,
                  cta_transfer_direction, cta_taped_thread_pool_name)
            (cta_taped_thread_pool_size)

    # Otel Collector health
    - name: collector-health
      interval: 30s
      rules:
      - record: otelcol_exporter_failures_total
        labels: { usecase: "ci" }
        expr: sum by (pod, exporter) (rate(otelcol_exporter_send_failed_metric_points[5m]))
      - record: otelcol_exporter_failures_total
        labels: { usecase: "ci" }
        expr: sum by (pod, exporter) (rate(otelcol_exporter_sent_metric_points_total[5m]))

    # Local Prometheus instance health
    - name: prometheus-health
      interval: 30s
      rules:
      - record: prometheus_remote_write_failures_total
        labels: { usecase: "ci" }
        expr: sum by (instance) (rate(prometheus_remote_storage_failed_samples_total[5m]))
      - record: prometheus_target_scrape_failures_total
        labels: { usecase: "ci" }
        expr: sum by (instance) (rate(prometheus_target_scrapes_exceeded_sample_limit_total[5m]))
      - record: prometheus_tsdb_wal_corruptions_total
        labels: { usecase: "ci" }
        expr: sum by (instance) (prometheus_tsdb_wal_corruptions_total)

    # Node metrics
    - name: node-health
      interval: 30s
      rules:
      - record: node_cpu_usage_percentage
        labels: { usecase: "ci" }
        expr: |
          100 * (1 - avg by (instance,namespace,node) (rate(node_cpu_seconds_total{mode="idle"}[1m])))
      - record: node_memory_usage_percentage
        labels: { usecase: "ci" }
        expr: |
          sum by (instance,namespace,node)
            ((1 - node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes) * 100)
      - record: node_disk_read_throughput
        labels: { usecase: "ci" }
        expr: |
          sum by (instance,namespace,node) (rate(node_disk_read_bytes_total[1m]))
      - record: node_disk_write_throughput
        labels: { usecase: "ci" }
        expr: |
          sum by (instance,namespace,node) (rate(node_disk_written_bytes_total[1m]))

    # Kube State Metrics (CI pods)
    - name: kube-state-metrics
      interval: 30s
      rules:
      - record: pod_cpu_system_seconds_total
        labels: { usecase: "ci" }
        expr: |
          sum by (instance, pod, namespace)
            (rate(container_cpu_system_seconds_total{container="",pod=~"cta.*|eos.*"}[1m]))
      - record: pod_memory_working_set_bytes
        labels: { usecase: "ci" }
        expr: |
          sum by (instance, pod, namespace)
            (container_memory_working_set_bytes{container="", pod=~"cta.*|eos.*"})
      - record: pod_disk_read_throughput
        labels: { usecase: "ci" }
        expr: |
          sum by (instance, namespace, pod)
            (rate(container_fs_reads_bytes_total{pod=~"cta.*|eos.*"}[1m]))
      - record: pod_disk_write_throughput
        labels: { usecase: "ci" }
        expr: |
          sum by (instance, namespace, pod)
            (rate(container_fs_writes_bytes_total{pod=~"cta.*|eos.*"}[1m]))
